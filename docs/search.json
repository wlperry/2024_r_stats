[
  {
    "objectID": "scripts/05_reading_files.html",
    "href": "scripts/05_reading_files.html",
    "title": "Reading and writing data",
    "section": "",
    "text": "The first and most important thing to be able to do is to read in a file - do stuff - and then save what you did to that file in the output directory. We will practice reading in CSV and Excel files.\n\n\n\nThis page has a link to all of the data files\nWe will use a mock data file that uses M&M’s\nM&M CSV file and also the M&M Excel file\n\n\n\n\n# load the libraries each time you restart R\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(lubridate)\nlibrary(readxl)\nlibrary(scales)\n\n\nAttaching package: 'scales'\n\nThe following object is masked from 'package:purrr':\n\n    discard\n\nThe following object is masked from 'package:readr':\n\n    col_factor\n\nlibrary(skimr)\nlibrary(janitor)\n\n\nAttaching package: 'janitor'\n\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test\n\nlibrary(patchwork)\n\n\n\n\n\n# Read in file using tidyverse code-----\nmm.df &lt;- read_csv(\"../data/mms.csv\")\n\nRows: 816 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (2): center, color\ndbl (2): diameter, mass\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\nNote that you can read in excel files in the same way.\n\n# Note you can read in excel files just as easy\n  mm_excel.df &lt;- read_excel(\"../data/mms.xlsx\")\n\n\n\n\n\nOne way is to click the blue trianlge in the environment tab in the upper right\nYou can also use code to inspect the structure of the dataset\n\n# data Structure\nstr(mm.df)\n\nspc_tbl_ [816 × 4] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ center  : chr [1:816] \"peanut butter\" \"peanut butter\" \"peanut butter\" \"peanut butter\" ...\n $ color   : chr [1:816] \"blue\" \"brown\" \"orange\" \"brown\" ...\n $ diameter: num [1:816] 16.2 16.5 15.5 16.3 15.6 ...\n $ mass    : num [1:816] 2.18 2.01 1.78 1.98 1.62 2.59 1.9 2.55 2.07 2.26 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   center = col_character(),\n  ..   color = col_character(),\n  ..   diameter = col_double(),\n  ..   mass = col_double()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\n# or\nglimpse(mm.df)\n\nRows: 816\nColumns: 4\n$ center   &lt;chr&gt; \"peanut butter\", \"peanut butter\", \"peanut butter\", \"peanut bu…\n$ color    &lt;chr&gt; \"blue\", \"brown\", \"orange\", \"brown\", \"yellow\", \"brown\", \"yello…\n$ diameter &lt;dbl&gt; 16.20, 16.50, 15.48, 16.32, 15.59, 17.43, 15.45, 17.30, 16.37…\n$ mass     &lt;dbl&gt; 2.18, 2.01, 1.78, 1.98, 1.62, 2.59, 1.90, 2.55, 2.07, 2.26, 1…\n\n\n\n\n\nBefore we go too far it is often important to save the modified data\nWe can use the read_r package to do this with write_csv\n\n# Saving files -----\n# We can save the file we just read in using \n# Saving dataframes -----\n# lets say you have made a lot of changes and its now time to save the dataframe\nwrite_csv(mm.df, \"../output/mm_output.csv\")"
  },
  {
    "objectID": "scripts/05_reading_files.html#how-to-read-in-data-and-write-data-back-to-a-csv-file",
    "href": "scripts/05_reading_files.html#how-to-read-in-data-and-write-data-back-to-a-csv-file",
    "title": "Reading and writing data",
    "section": "",
    "text": "The first and most important thing to be able to do is to read in a file - do stuff - and then save what you did to that file in the output directory. We will practice reading in CSV and Excel files."
  },
  {
    "objectID": "scripts/05_reading_files.html#data-for-the-exercise",
    "href": "scripts/05_reading_files.html#data-for-the-exercise",
    "title": "Reading and writing data",
    "section": "",
    "text": "This page has a link to all of the data files\nWe will use a mock data file that uses M&M’s\nM&M CSV file and also the M&M Excel file"
  },
  {
    "objectID": "scripts/05_reading_files.html#load-libraries",
    "href": "scripts/05_reading_files.html#load-libraries",
    "title": "Reading and writing data",
    "section": "",
    "text": "# load the libraries each time you restart R\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(lubridate)\nlibrary(readxl)\nlibrary(scales)\n\n\nAttaching package: 'scales'\n\nThe following object is masked from 'package:purrr':\n\n    discard\n\nThe following object is masked from 'package:readr':\n\n    col_factor\n\nlibrary(skimr)\nlibrary(janitor)\n\n\nAttaching package: 'janitor'\n\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test\n\nlibrary(patchwork)"
  },
  {
    "objectID": "scripts/05_reading_files.html#read-in-the-file",
    "href": "scripts/05_reading_files.html#read-in-the-file",
    "title": "Reading and writing data",
    "section": "",
    "text": "# Read in file using tidyverse code-----\nmm.df &lt;- read_csv(\"../data/mms.csv\")\n\nRows: 816 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (2): center, color\ndbl (2): diameter, mass\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\nNote that you can read in excel files in the same way.\n\n# Note you can read in excel files just as easy\n  mm_excel.df &lt;- read_excel(\"../data/mms.xlsx\")"
  },
  {
    "objectID": "scripts/05_reading_files.html#look-at-dataframe-structure",
    "href": "scripts/05_reading_files.html#look-at-dataframe-structure",
    "title": "Reading and writing data",
    "section": "",
    "text": "One way is to click the blue trianlge in the environment tab in the upper right\nYou can also use code to inspect the structure of the dataset\n\n# data Structure\nstr(mm.df)\n\nspc_tbl_ [816 × 4] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ center  : chr [1:816] \"peanut butter\" \"peanut butter\" \"peanut butter\" \"peanut butter\" ...\n $ color   : chr [1:816] \"blue\" \"brown\" \"orange\" \"brown\" ...\n $ diameter: num [1:816] 16.2 16.5 15.5 16.3 15.6 ...\n $ mass    : num [1:816] 2.18 2.01 1.78 1.98 1.62 2.59 1.9 2.55 2.07 2.26 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   center = col_character(),\n  ..   color = col_character(),\n  ..   diameter = col_double(),\n  ..   mass = col_double()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\n# or\nglimpse(mm.df)\n\nRows: 816\nColumns: 4\n$ center   &lt;chr&gt; \"peanut butter\", \"peanut butter\", \"peanut butter\", \"peanut bu…\n$ color    &lt;chr&gt; \"blue\", \"brown\", \"orange\", \"brown\", \"yellow\", \"brown\", \"yello…\n$ diameter &lt;dbl&gt; 16.20, 16.50, 15.48, 16.32, 15.59, 17.43, 15.45, 17.30, 16.37…\n$ mass     &lt;dbl&gt; 2.18, 2.01, 1.78, 1.98, 1.62, 2.59, 1.90, 2.55, 2.07, 2.26, 1…"
  },
  {
    "objectID": "scripts/05_reading_files.html#saving-files",
    "href": "scripts/05_reading_files.html#saving-files",
    "title": "Reading and writing data",
    "section": "",
    "text": "Before we go too far it is often important to save the modified data\nWe can use the read_r package to do this with write_csv\n\n# Saving files -----\n# We can save the file we just read in using \n# Saving dataframes -----\n# lets say you have made a lot of changes and its now time to save the dataframe\nwrite_csv(mm.df, \"../output/mm_output.csv\")"
  },
  {
    "objectID": "scripts/05_reading_files.html#graphing-data",
    "href": "scripts/05_reading_files.html#graphing-data",
    "title": "Reading and writing data",
    "section": "Graphing data",
    "text": "Graphing data\nI feel that graphing is the key to all data analysis. If you can look at your data you can begin to see patterns that you may have predicted and want to test statistically. You will also be able to see outliers that exist that might affect resutls faster than looking at summary statistics.\nUsing proper GGPlot code you are supposed to have dat = , y = and x = ….\nI have found that these are not necessary most of the time and we can talk about this later.\n\n# GGplot uses layers to build a graph\n\nggplot(data=mm.df, aes(x=color, y=diameter)) + # this sets up data \n  geom_point() # this adds a geometry to present the data from above\n\n\n\n\nBecause GGPlot builds things in layers you can add other geoms to the plot. Below you should try this code and see what happens when you put in + after geom_line() and then add geom_boxplot().\n\n# Add geom_point() -----\n# Add points to the graph below using geom_point()\nggplot(mm.df, aes(x=color, y=diameter)) +\n  geom_point()"
  },
  {
    "objectID": "scripts/05_reading_files.html#adding-axes-labels",
    "href": "scripts/05_reading_files.html#adding-axes-labels",
    "title": "Reading and writing data",
    "section": "Adding axes labels",
    "text": "Adding axes labels\nYou can add in simple axes labels that are not formatted. Using the labs(x= ” “, y =” “) statement. You can add in line breaks by putting in a \\n in the statement that you have below.\n\n# Adding axes labels ----\nggplot(mm.df, aes(x=color, y=diameter)) +\n  geom_boxplot() +\n  geom_point() +\n  labs(x = \"Color\", y = \"Diameter\")"
  },
  {
    "objectID": "scripts/05_reading_files.html#formatted-axes-labels",
    "href": "scripts/05_reading_files.html#formatted-axes-labels",
    "title": "Reading and writing data",
    "section": "Formatted axes labels",
    "text": "Formatted axes labels\nWhat I find really nice is being able to create formatted axes labels. You can do this a few ways but I have found the that the expression statement works the best for my needs. You can add in a ~ to add a space between symbols and a * will connect things without a space.\n\n# Label expressions -----\n# Adding special formatting to labels\nggplot(mm.df, aes(x=color, y=diameter)) +\n  geom_boxplot() +\n  geom_point() +\n  labs(x = \"color\", y = expression(bold(\"Diameter (\"*mu*\"*1000)\")))"
  },
  {
    "objectID": "scripts/99_example_data_files.html",
    "href": "scripts/99_example_data_files.html",
    "title": "Example Data Files",
    "section": "",
    "text": "Here are the example dataframes -\n\n\n\nDataframe\nCSV version\n\nXLSX version\n\n\n\n\nM&M data\nm&m csv\n\nm&m excel"
  },
  {
    "objectID": "scripts/04_project_setup.html",
    "href": "scripts/04_project_setup.html",
    "title": "Project Management",
    "section": "",
    "text": "So the first thing to think about in my opinion is the workflow or dataflow:\n\nWhat is the source and format of your data?\n\nwhat are the variables and units and how will you name them\n\ncontrolled vocabulary list\n\ndata structure in columns\n\n\nWhat is the final objective and use of your data and what output?\n\nwhat is the most flexible output\n\ngraphs\n\nsummary statistics\n\nstatistical analyses\n\n\nWhat is the flow of data\n\nsource and update frequency\nQA/QC and flagging of data\nTransformations or calculations to be made\nFinal data output for use - note never write to original dataframe\nSummary statistics\nGraphs\nStatistical Analyses\nReports with markdown\nAnnotate scripts and metadata\n\n\nSet up directory structure\n\nR Project Directory\n\nscripts/code\ndocuments\ndata\nfigures / output\nfinalized_data\n\n\n\n\n\n\n\n\nThinking about your data source first is important. Using a controlled vocabulary that references names of variables the same from project to project is critical. Defining these in a metadata document with the vocabulary and the units for each term so that future users can figure out what your codes mean is also useful.\n\n\n\nAs part of controlled vocabulary, the way you type the variable names is also important and also important to be consistent. I have found snake case to be the best for me and using the package Janitor works well to fix messy file names. The main problem is variable names with spaces requires back ticks (variable name) to use them and special characters (`!@#$%^&* and u(micro) etc.) are coded differently on different operating systems and create chaos. The different styles are below:\n\nsnake case - looks_like_this - separated by _ and all lower case and often most popular\nperiod separated - looks.like.this - separated by periods - may get confused with other commands\nlower camel case - looksLikeThis - ever word is capitilized after the first - often harder to type with all the shift caps\nupper camel case - LooksLikeThis - all words capitilized\nall lower case - lookslikethis - I find it messy and hard to read\n\nthe key is that you should have no spaces or special characters. If you do have spaces you use the back tick abc xyz on either side of the variable to call it.\nSpecial characters are often coded differently in mac and pc computers and will cause more headaches than you have after St. Patricks Day.\n\n\n\nKeeping a list of transformations and conversions can be helpful in coding and if it is in the meta data file, you can copy the transformations out of the document and if there are mistakes people can track it down fast.\n\n\n\nR uses a column format and all the data in a column has to be of the same type. You can, however, reference data by row and column as in excel.\nThe most common data formats you will run into are:\n\nNumeric - can be double or integer but that is not as important\nCharacter - text fields\nFactors - displayed often as text but is as levels behind the scenes\nDate - date format or PosixLt or Date\n\nnote this is in days since 1970-01-01 I believe\n\nDate time - date and time format together or PosixCt\n\nthis is in seconds since 1970-01-01 00:00:00\nthis will be critical for many of you\n\nNote that if you mix formats within a column some of the variables will be converted to NA if say you have a column that is a character column which has mixed numbers and text and is then converted to numeric\n\n\n\n\nTypically when we enter data it is in wide format where an identifier is in the first column and the various variables are in separate columns. This is what is often easiest to enter into excel or wherever it is entered originally.\nThis format is often more difficult to work with in R and GGPlot so it is converted to long format where there is a column of identifiers, a column of variable names, and a column of values. The switch between these formats is often rather easy so it does not matter what format it is in.\nwide format:\nFor the M&M data set this would look like:\nColumns across the top would be:\n\ncenter - type of center - peanut or chocolate etc\ncolor - the outter shell color\ndiameter - the size\nmass - the weight\n\nlong format:\nThis would condense this format to fewer columns repeating center and color and have a column called dimension and one called values. The dimension would be diameter or mass and the value woudl be the value. This is not that effective in this small data set but it invalualbe in larger data sets. It also makes summary stats and graphing easier:\n\ncenter - type of center - peanut or chocolate etc\ncolor - the outer shell color\ndimension - diameter or mass\nvalue - either the diameter or weight\n\n\n\n\nI find it useful to maintain a read only file of the original data and never write to this file other than the original QA/QC flagging of the data if even then. I usually read from this file and save it to the finalized data folder where the data has been cleaned formatted and basic calculations done on it.\n\n\n\n\nIt is often very helpful prior to doing any code work to think about what the final output will look like and what the original data looks like and the steps between these two points.\n\n\n\nHaving a consistent project directory structure where code, data, and text is stored makes it easy to look at different directories and find what you are looking for. That is why I use the following structure. Choose what works for you and stick with it… please\n\n\n\nr_projects\n\nscripts\ndocuments\ndata\nfigures or output\nfinal_data\n\n\n\nUsing projects in R is super useful and you don’t have to worry about setting directories (setwd(*C:*)) between a mac and windows machine and all the paths are relative in there when you reference data or output directories and is the same on windows and mac.\n\n\n\nFrom the site File organization and best practices and Prime Hints naming files has many good practices. Of these the main theme is:\n\nUse a consistent naming theme\n\nuse date_term1_term2.xxx\nno spaces or other fancy characters\nmake the names human understandable\n\nUse natural ordering of files\n\nuse date at front or somewhere so you know the version\nuse logical ordering like 01_ 02_ 03_\n\nAvoid things like\n\nfinal thesis proposal.docx - I deal with many students and this is not helpful\n\n\n\n\n\nFor the love of all that is good - be sure to annotate you code using the # and whatever text helps describe the process you are doing - it will make the code easier to read and evaluate later when you are trying to figure out something really fast. You can also use it to search for code snippets as you are going along.\nMetadata files that document what you are doing and why and what the various conversions and statistical transformations are can be of great use later on as well. It is often challenging to figure out what the units are in for various variables or what they actually mean.\n\n\n\n\n\nYou can write a comment # and then follow it with text and then 4 dashes ---- or #### and it will create a note in the outline view\n\n\n\nYou should use comments # with text behind it to annotate the purpose of what your are doing and what is happening in the code chunk below.\n\n\n\n\nSo lets start installing R and R studio\nR is its own program and can be retrieved from R Cran\n\nR Studio is a program that makes the interface and usability of R easier in my opinion and can be retrieved here R Studio\nWhen you get these installed we can load up R studio and look at the interface.\n\n\nStart R studio and you should see:\n\n\n\n\nNow to set up a new project in a new directory\n\nClick File - New Project\n\nclick New Directory\n\nclick New Project\n\nThen enter the name of the directory you want - Note it is helpful to have a directory of r_projects that you will store all your r projects in.\n\nThen in the upper right is a name of a project - test in this case - and the files will have the name of the project you will either open when you start RStudio or that you double click to open the project\n\nNow I typically create directories within this project to organize everything using the following scheme.\n\nAll projects have the same exact set up.\n\nScripts - where all the script files go\nData - where the original data goes and is never written to\nFigures - where you save pdf files of your graphs\nOutput - output of modified data\nDocuments - documents that relate to the project and meta data if needed\nThemes - a place to store themes for graphs - more later on\n\n\n\nnaming of scripts - note I now name scripts 01_import_and_clean.R and then in order from there in what is done."
  },
  {
    "objectID": "scripts/04_project_setup.html#steps-to-consider",
    "href": "scripts/04_project_setup.html#steps-to-consider",
    "title": "Project Management",
    "section": "",
    "text": "So the first thing to think about in my opinion is the workflow or dataflow:\n\nWhat is the source and format of your data?\n\nwhat are the variables and units and how will you name them\n\ncontrolled vocabulary list\n\ndata structure in columns\n\n\nWhat is the final objective and use of your data and what output?\n\nwhat is the most flexible output\n\ngraphs\n\nsummary statistics\n\nstatistical analyses\n\n\nWhat is the flow of data\n\nsource and update frequency\nQA/QC and flagging of data\nTransformations or calculations to be made\nFinal data output for use - note never write to original dataframe\nSummary statistics\nGraphs\nStatistical Analyses\nReports with markdown\nAnnotate scripts and metadata\n\n\nSet up directory structure\n\nR Project Directory\n\nscripts/code\ndocuments\ndata\nfigures / output\nfinalized_data"
  },
  {
    "objectID": "scripts/04_project_setup.html#data-source-format",
    "href": "scripts/04_project_setup.html#data-source-format",
    "title": "Project Management",
    "section": "",
    "text": "Thinking about your data source first is important. Using a controlled vocabulary that references names of variables the same from project to project is critical. Defining these in a metadata document with the vocabulary and the units for each term so that future users can figure out what your codes mean is also useful.\n\n\n\nAs part of controlled vocabulary, the way you type the variable names is also important and also important to be consistent. I have found snake case to be the best for me and using the package Janitor works well to fix messy file names. The main problem is variable names with spaces requires back ticks (variable name) to use them and special characters (`!@#$%^&* and u(micro) etc.) are coded differently on different operating systems and create chaos. The different styles are below:\n\nsnake case - looks_like_this - separated by _ and all lower case and often most popular\nperiod separated - looks.like.this - separated by periods - may get confused with other commands\nlower camel case - looksLikeThis - ever word is capitilized after the first - often harder to type with all the shift caps\nupper camel case - LooksLikeThis - all words capitilized\nall lower case - lookslikethis - I find it messy and hard to read\n\nthe key is that you should have no spaces or special characters. If you do have spaces you use the back tick abc xyz on either side of the variable to call it.\nSpecial characters are often coded differently in mac and pc computers and will cause more headaches than you have after St. Patricks Day.\n\n\n\nKeeping a list of transformations and conversions can be helpful in coding and if it is in the meta data file, you can copy the transformations out of the document and if there are mistakes people can track it down fast.\n\n\n\nR uses a column format and all the data in a column has to be of the same type. You can, however, reference data by row and column as in excel.\nThe most common data formats you will run into are:\n\nNumeric - can be double or integer but that is not as important\nCharacter - text fields\nFactors - displayed often as text but is as levels behind the scenes\nDate - date format or PosixLt or Date\n\nnote this is in days since 1970-01-01 I believe\n\nDate time - date and time format together or PosixCt\n\nthis is in seconds since 1970-01-01 00:00:00\nthis will be critical for many of you\n\nNote that if you mix formats within a column some of the variables will be converted to NA if say you have a column that is a character column which has mixed numbers and text and is then converted to numeric\n\n\n\n\nTypically when we enter data it is in wide format where an identifier is in the first column and the various variables are in separate columns. This is what is often easiest to enter into excel or wherever it is entered originally.\nThis format is often more difficult to work with in R and GGPlot so it is converted to long format where there is a column of identifiers, a column of variable names, and a column of values. The switch between these formats is often rather easy so it does not matter what format it is in.\nwide format:\nFor the M&M data set this would look like:\nColumns across the top would be:\n\ncenter - type of center - peanut or chocolate etc\ncolor - the outter shell color\ndiameter - the size\nmass - the weight\n\nlong format:\nThis would condense this format to fewer columns repeating center and color and have a column called dimension and one called values. The dimension would be diameter or mass and the value woudl be the value. This is not that effective in this small data set but it invalualbe in larger data sets. It also makes summary stats and graphing easier:\n\ncenter - type of center - peanut or chocolate etc\ncolor - the outer shell color\ndimension - diameter or mass\nvalue - either the diameter or weight\n\n\n\n\nI find it useful to maintain a read only file of the original data and never write to this file other than the original QA/QC flagging of the data if even then. I usually read from this file and save it to the finalized data folder where the data has been cleaned formatted and basic calculations done on it."
  },
  {
    "objectID": "scripts/04_project_setup.html#data-flow",
    "href": "scripts/04_project_setup.html#data-flow",
    "title": "Project Management",
    "section": "",
    "text": "It is often very helpful prior to doing any code work to think about what the final output will look like and what the original data looks like and the steps between these two points."
  },
  {
    "objectID": "scripts/04_project_setup.html#project-directory-structure",
    "href": "scripts/04_project_setup.html#project-directory-structure",
    "title": "Project Management",
    "section": "",
    "text": "Having a consistent project directory structure where code, data, and text is stored makes it easy to look at different directories and find what you are looking for. That is why I use the following structure. Choose what works for you and stick with it… please\n\n\n\nr_projects\n\nscripts\ndocuments\ndata\nfigures or output\nfinal_data\n\n\n\nUsing projects in R is super useful and you don’t have to worry about setting directories (setwd(*C:*)) between a mac and windows machine and all the paths are relative in there when you reference data or output directories and is the same on windows and mac."
  },
  {
    "objectID": "scripts/04_project_setup.html#file-names",
    "href": "scripts/04_project_setup.html#file-names",
    "title": "Project Management",
    "section": "",
    "text": "From the site File organization and best practices and Prime Hints naming files has many good practices. Of these the main theme is:\n\nUse a consistent naming theme\n\nuse date_term1_term2.xxx\nno spaces or other fancy characters\nmake the names human understandable\n\nUse natural ordering of files\n\nuse date at front or somewhere so you know the version\nuse logical ordering like 01_ 02_ 03_\n\nAvoid things like\n\nfinal thesis proposal.docx - I deal with many students and this is not helpful"
  },
  {
    "objectID": "scripts/04_project_setup.html#annotations-and-metadata-files",
    "href": "scripts/04_project_setup.html#annotations-and-metadata-files",
    "title": "Project Management",
    "section": "",
    "text": "For the love of all that is good - be sure to annotate you code using the # and whatever text helps describe the process you are doing - it will make the code easier to read and evaluate later when you are trying to figure out something really fast. You can also use it to search for code snippets as you are going along.\nMetadata files that document what you are doing and why and what the various conversions and statistical transformations are can be of great use later on as well. It is often challenging to figure out what the units are in for various variables or what they actually mean."
  },
  {
    "objectID": "scripts/04_project_setup.html#rstudio-specifics",
    "href": "scripts/04_project_setup.html#rstudio-specifics",
    "title": "Project Management",
    "section": "",
    "text": "You can write a comment # and then follow it with text and then 4 dashes ---- or #### and it will create a note in the outline view\n\n\n\nYou should use comments # with text behind it to annotate the purpose of what your are doing and what is happening in the code chunk below."
  },
  {
    "objectID": "scripts/04_project_setup.html#installing-r",
    "href": "scripts/04_project_setup.html#installing-r",
    "title": "Project Management",
    "section": "",
    "text": "So lets start installing R and R studio\nR is its own program and can be retrieved from R Cran\n\nR Studio is a program that makes the interface and usability of R easier in my opinion and can be retrieved here R Studio\nWhen you get these installed we can load up R studio and look at the interface.\n\n\nStart R studio and you should see:\n\n\n\n\nNow to set up a new project in a new directory\n\nClick File - New Project\n\nclick New Directory\n\nclick New Project\n\nThen enter the name of the directory you want - Note it is helpful to have a directory of r_projects that you will store all your r projects in.\n\nThen in the upper right is a name of a project - test in this case - and the files will have the name of the project you will either open when you start RStudio or that you double click to open the project\n\nNow I typically create directories within this project to organize everything using the following scheme.\n\nAll projects have the same exact set up.\n\nScripts - where all the script files go\nData - where the original data goes and is never written to\nFigures - where you save pdf files of your graphs\nOutput - output of modified data\nDocuments - documents that relate to the project and meta data if needed\nThemes - a place to store themes for graphs - more later on\n\n\n\nnaming of scripts - note I now name scripts 01_import_and_clean.R and then in order from there in what is done."
  },
  {
    "objectID": "scripts/about.html",
    "href": "scripts/about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "scripts/index.html",
    "href": "scripts/index.html",
    "title": "Intro Stats 2024",
    "section": "",
    "text": "2024 R stats for biology students\nThis is a seminar course on using R for common statistical tests that you might do in your thesis. This will be an initial introduction to R and RStudio using a lot of the materials from our introductory biostatistics course. This site will also serve as a repository for the course materials we cover and also the specialized statistics we cover at the end of the term that we will do for your specific work.\nI have found R to be a life changing program and use it nearly every day now.\nHere is a page with all the example data files - Click HERE\nTopics to be covered:\n\nResources that are super helpful in using R - a lot of links and ideas\nPrior to class - setting up R and RStudio and installing essential libraries\nInstall packages and load libraries\nBasics of project management\nReading in and writing to files"
  },
  {
    "objectID": "scripts/01_resources.html",
    "href": "scripts/01_resources.html",
    "title": "R Resources",
    "section": "",
    "text": "This is a set of resources I have found to be super helpful in learning R.\nI will follow the ideas presented in R for Data Science (2e)\n\n\n\n\n\nA great resource for looking up issues is StackOverflow \nFor help with statistics I found R Companion to be a GREAT resource"
  },
  {
    "objectID": "scripts/02_installing_r.html",
    "href": "scripts/02_installing_r.html",
    "title": "Installing R",
    "section": "",
    "text": "R is a standalone program that can be used to do all the work we do. RStudio sits on top of R and allows the user to see a lot more of what is going on behind the scenes like what is loaded in the environment or dataframes that are loaded or graphs that have been made.\nFirst we will install R:\nGo to CRAN to download R for your particular computer system you are using. Note all R versions are named after Charlie Brown episodes. You will need to update this say every 6 months but downloading it and reinstalling\nCRAN is located here\n\n\n\n\n\n\n\n\nThen you need to go to POSIT to install RStudio here\nNote they also have a link to R. Once installed you should be able open it and it will be a running version of RStudio. Then we are on to installing packages."
  },
  {
    "objectID": "scripts/02_installing_r.html#installing-r",
    "href": "scripts/02_installing_r.html#installing-r",
    "title": "Installing R",
    "section": "",
    "text": "R is a standalone program that can be used to do all the work we do. RStudio sits on top of R and allows the user to see a lot more of what is going on behind the scenes like what is loaded in the environment or dataframes that are loaded or graphs that have been made.\nFirst we will install R:\nGo to CRAN to download R for your particular computer system you are using. Note all R versions are named after Charlie Brown episodes. You will need to update this say every 6 months but downloading it and reinstalling\nCRAN is located here"
  },
  {
    "objectID": "scripts/02_installing_r.html#installing-r-studio",
    "href": "scripts/02_installing_r.html#installing-r-studio",
    "title": "Installing R",
    "section": "",
    "text": "Then you need to go to POSIT to install RStudio here\nNote they also have a link to R. Once installed you should be able open it and it will be a running version of RStudio. Then we are on to installing packages."
  },
  {
    "objectID": "scripts/03_installing_libraries.html",
    "href": "scripts/03_installing_libraries.html",
    "title": "Installing libraries",
    "section": "",
    "text": "Libraries are sets of code that are stored either individually or as groups in packages that when installed add a lot of functionality to R. The tidyverse package for instance has a lot of libraries in it that make using R a lot easier for beginners and advanced users. Tidyverse builds on base R to make the syntax similar across many of the tasks you will want to do.\n\n\nYou will install these one time and then you need to load the libraries each time you use R and I usually have them loaded at the top of each script. Below is how to install libraries\ninstall.packages(\"devtools\") # install new things from developmental sources\ninstall.packages(\"tidyverse\") # dplyr and piping and ggplot etc\ninstall.packages(\"lubridate\") # dates and times\ninstall.packages(\"readxl\") # read in excel files\ninstall.packages(\"janitor\") # clean up excel imports\ninstall.packages(\"patchwork\") # arrange multiple plots per page\ninstall.packages(\"skimr\") # quick summary stats\ninstall.packages(\"plotly\") # cool ggplot things\ninstall.packages(\"scales\") # scales on ggplot axes\n\n\n\nThis is how to load the libraries at the start of each script.\nlibrary(tidyverse) \nlibrary(lubridate) \nlibrary(scales) \nlibrary(readxl) \nlibrary(skimr) \nlibrary(janitor) \nlibrary(patchwork)\n\n\n\ninstall.packages(\"ggThemeAssist\") # helps reformat code - only run library one time\ninstall.packages(\"styler\") # allows you to reformat code to look like a pro!!\n\nlibrary(ggThemeAssist)\nlibrary(styler) \nYou may need to go to the View in the menu and click show toolbar to see this\n\n\n\nAddins menu\n\n\n\n\n\nThese are some of the better vetted statistical packages in my opinioon\n\ninstall.packages(\"car\") # stats and ANOVA - essential \ninstall.packages(\"emmeans\") # estimated marginal means for unbalanced designs \ninstall.packages(\"multcomView\") # paired comparisons - note this will interfear with DPLYR!!\ninstall.packages(\"Rmisc\") # stats \ninstall.packages(\"Hmisc\") # stats install.packages(\"broom\") # output models cleanly \n\n\n\n{install.packages(\"GGally\") # special ggplot graphs} install.packages(\"corrplot\") # correlation plot matricies install.packages(\"survminer\") # survival analysis  install.packages(\"survival\") # survival analysis  install.packages(\"pwr\") # power analysis  install.packages(\"vegan\") # PCA and other sorts of multidimensional  install.packages(\"factoextra\") # more PCA# mixed models  install.packages(\"lmerTest\") # mixed model Anovas  install.packages(\"blme\") # Bayesian mixed model Anovas\n\n\n\ninstall.packages(\"hms\") # useful for time series    \ninstall.packages(\"akima\") # imputing new values         \ninstall.packages(\"RMySQL\") # access MySQLserver     \ninstall.packages(\"rLakeAnalyzer\") # used for the lake analyzer scripts \ninstall.packages(\"LakeMetabolizer\") #\ninstall.packages(\"colorRamps\") # adds cool color templates"
  },
  {
    "objectID": "scripts/03_installing_libraries.html#packages-libraries",
    "href": "scripts/03_installing_libraries.html#packages-libraries",
    "title": "Installing libraries",
    "section": "",
    "text": "Libraries are sets of code that are stored either individually or as groups in packages that when installed add a lot of functionality to R. The tidyverse package for instance has a lot of libraries in it that make using R a lot easier for beginners and advanced users. Tidyverse builds on base R to make the syntax similar across many of the tasks you will want to do.\n\n\nYou will install these one time and then you need to load the libraries each time you use R and I usually have them loaded at the top of each script. Below is how to install libraries\ninstall.packages(\"devtools\") # install new things from developmental sources\ninstall.packages(\"tidyverse\") # dplyr and piping and ggplot etc\ninstall.packages(\"lubridate\") # dates and times\ninstall.packages(\"readxl\") # read in excel files\ninstall.packages(\"janitor\") # clean up excel imports\ninstall.packages(\"patchwork\") # arrange multiple plots per page\ninstall.packages(\"skimr\") # quick summary stats\ninstall.packages(\"plotly\") # cool ggplot things\ninstall.packages(\"scales\") # scales on ggplot axes\n\n\n\nThis is how to load the libraries at the start of each script.\nlibrary(tidyverse) \nlibrary(lubridate) \nlibrary(scales) \nlibrary(readxl) \nlibrary(skimr) \nlibrary(janitor) \nlibrary(patchwork)\n\n\n\ninstall.packages(\"ggThemeAssist\") # helps reformat code - only run library one time\ninstall.packages(\"styler\") # allows you to reformat code to look like a pro!!\n\nlibrary(ggThemeAssist)\nlibrary(styler) \nYou may need to go to the View in the menu and click show toolbar to see this\n\n\n\nAddins menu\n\n\n\n\n\nThese are some of the better vetted statistical packages in my opinioon\n\ninstall.packages(\"car\") # stats and ANOVA - essential \ninstall.packages(\"emmeans\") # estimated marginal means for unbalanced designs \ninstall.packages(\"multcomView\") # paired comparisons - note this will interfear with DPLYR!!\ninstall.packages(\"Rmisc\") # stats \ninstall.packages(\"Hmisc\") # stats install.packages(\"broom\") # output models cleanly \n\n\n\n{install.packages(\"GGally\") # special ggplot graphs} install.packages(\"corrplot\") # correlation plot matricies install.packages(\"survminer\") # survival analysis  install.packages(\"survival\") # survival analysis  install.packages(\"pwr\") # power analysis  install.packages(\"vegan\") # PCA and other sorts of multidimensional  install.packages(\"factoextra\") # more PCA# mixed models  install.packages(\"lmerTest\") # mixed model Anovas  install.packages(\"blme\") # Bayesian mixed model Anovas\n\n\n\ninstall.packages(\"hms\") # useful for time series    \ninstall.packages(\"akima\") # imputing new values         \ninstall.packages(\"RMySQL\") # access MySQLserver     \ninstall.packages(\"rLakeAnalyzer\") # used for the lake analyzer scripts \ninstall.packages(\"LakeMetabolizer\") #\ninstall.packages(\"colorRamps\") # adds cool color templates"
  }
]